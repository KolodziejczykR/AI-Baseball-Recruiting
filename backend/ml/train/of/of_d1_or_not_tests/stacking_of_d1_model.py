import pandas as pd
import numpy as np
import os
import joblib
import pickle
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, recall_score, balanced_accuracy_score, precision_score
from sklearn.ensemble import VotingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
import xgboost as xgb
import lightgbm as lgb
import catboost as cb
from sklearn.cluster import KMeans
import optuna
from sklearn.calibration import CalibratedClassifierCV
import warnings
warnings.filterwarnings('ignore')

# Create directory for saving models
models_dir = '/Users/ryankolodziejczyk/Documents/AI Baseball Recruitment/code/backend/ml/train/of/of_d1_or_not_tests/saved_stacked_meta_models'
os.makedirs(models_dir, exist_ok=True)
print(f"üìÅ Models will be saved to: {models_dir}")

print("üöÄ STACKING ENSEMBLE OUTFIELDER D1 MODEL")
print("=" * 80)
print("Advanced Approach: Multi-Level Stacking + Calibrated Predictions + Custom Objectives")
print("Level 1: Diverse Base Models | Level 2: Meta-Learner | Level 3: Calibration")
print("=" * 80)

# Load data
csv_path = '/Users/ryankolodziejczyk/Documents/AI Baseball Recruitment/code/backend/data/hitters/of_feat_eng_d1_or_not.csv'
df = pd.read_csv(csv_path)

print(f"Loaded outfield dataset with {len(df)} players")
print(f"D1 Distribution: {df['d1_or_not'].value_counts()}")
print(f"D1 Rate: {df['d1_or_not'].mean():.2%}")

# Drop rows with missing critical features
df = df.dropna(subset=['of_velo', 'player_region'])

# Create categorical encodings
df = pd.get_dummies(df, columns=['player_region', 'throwing_hand', 'hitting_handedness'], 
                   prefix_sep='_', drop_first=True)

# ============================================================================
# ENHANCED FEATURE ENGINEERING FOR STACKING
# ============================================================================
print("\nüîß Enhanced Feature Engineering for Stacking...")

# Core metrics
df['power_speed'] = df['exit_velo_max'] / df['sixty_time']
df['of_velo_sixty_ratio'] = df['of_velo'] / df['sixty_time']
df['height_weight'] = df['height'] * df['weight']

# Percentile features
percentile_features = ['exit_velo_max', 'of_velo', 'sixty_time', 'height', 'weight', 'power_speed']
for col in percentile_features:
    if col in df.columns:
        if col == 'sixty_time':  # Lower is better
            df[f'{col}_percentile'] = (1 - df[col].rank(pct=True)) * 100
        else:  # Higher is better
            df[f'{col}_percentile'] = df[col].rank(pct=True) * 100

# Advanced feature interactions
df['power_per_pound'] = df['exit_velo_max'] / df['weight']
df['exit_to_sixty_ratio'] = df['exit_velo_max'] / df['sixty_time']
df['speed_size_efficiency'] = (df['height'] * df['weight']) / (df['sixty_time'] ** 2)
df['athletic_index'] = (df['power_speed'] * df['height'] * df['weight']) / df['sixty_time']

# Elite thresholds
df['elite_exit_velo'] = (df['exit_velo_max'] >= df['exit_velo_max'].quantile(0.75)).astype(int)
df['elite_of_velo'] = (df['of_velo'] >= df['of_velo'].quantile(0.75)).astype(int)
df['elite_speed'] = (df['sixty_time'] <= df['sixty_time'].quantile(0.25)).astype(int)
df['elite_size'] = ((df['height'] >= df['height'].quantile(0.6)) & 
                   (df['weight'] >= df['weight'].quantile(0.6))).astype(int)

# Multi-tool features
df['tool_count'] = (df['elite_exit_velo'] + df['elite_of_velo'] + 
                   df['elite_speed'] + df['elite_size'])
df['is_multi_tool'] = (df['tool_count'] >= 2).astype(int)

# Advanced composites
df['d1_power_threshold'] = (df['exit_velo_max'] >= 88).astype(int)
df['d1_arm_threshold'] = (df['of_velo'] >= 80).astype(int)
df['d1_speed_threshold'] = (df['sixty_time'] <= 7.2).astype(int)
df['d1_size_threshold'] = ((df['height'] >= 70) & (df['weight'] >= 165)).astype(int)

# Polynomial features for non-linear relationships
df['exit_velo_squared'] = df['exit_velo_max'] ** 2
df['sixty_time_inv'] = 1 / df['sixty_time']
df['of_velo_log'] = np.log1p(df['of_velo'])

# Regional advantages
regional_cols = [col for col in df.columns if 'player_region_' in col]
if regional_cols:
    region_weights = {}
    for col in regional_cols:
        region_weights[col] = df[df[col] == 1]['d1_or_not'].mean()
    
    df['region_d1_advantage'] = 0
    for col, weight in region_weights.items():
        df['region_d1_advantage'] += df[col] * weight

# Feature clustering - create similarity groups
feature_cols = ['exit_velo_max', 'of_velo', 'sixty_time', 'height', 'weight']
scaler_cluster = StandardScaler()
cluster_features = scaler_cluster.fit_transform(df[feature_cols])
kmeans = KMeans(n_clusters=5, random_state=42)
df['player_cluster'] = kmeans.fit_predict(cluster_features)
df = pd.get_dummies(df, columns=['player_cluster'], prefix='cluster', drop_first=True)

print(f"‚úì Created {len(df.columns) - 2} enhanced features for stacking")

# ============================================================================
# PREPARE DATA FOR STACKING
# ============================================================================
print("\nüìä Preparing data for multi-level stacking...")

# Prepare features
drop_cols = ['d1_or_not', 'primary_position']
X = df.drop(columns=drop_cols)
y = df['d1_or_not']

# Clean data
X = X.replace([np.inf, -np.inf], np.nan).fillna(0)
for col in X.select_dtypes(include=[np.number]).columns:
    Q1, Q3 = X[col].quantile(0.01), X[col].quantile(0.99)
    IQR = Q3 - Q1
    X[col] = X[col].clip(Q1 - 1.5*IQR, Q3 + 1.5*IQR)

# Strategic train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print(f"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}")
print(f"Train D1 rate: {y_train.mean():.2%}, Test D1 rate: {y_test.mean():.2%}")

# ============================================================================
# LEVEL 1: DIVERSE BASE MODELS WITH CUSTOM OBJECTIVES
# ============================================================================
print("\nüéØ LEVEL 1: Training Diverse Base Models with Custom Objectives...")

# Custom objective function focusing on accuracy + balanced recall
def custom_objective_score(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    recall_0 = recall_score(y_true, y_pred, pos_label=0)
    recall_1 = recall_score(y_true, y_pred, pos_label=1)
    balanced_acc = balanced_accuracy_score(y_true, y_pred)
    
    # Weight accuracy heavily, but ensure balanced recall
    return (accuracy * 0.5 + balanced_acc * 0.3 + (recall_0 + recall_1) * 0.2)

# XGBoost with Focal Loss approach
print("\n1. XGBoost with Advanced Parameters...")
def xgb_objective(trial):
    params = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'learning_rate': trial.suggest_float('eta', 0.005, 0.3, log=True),
        'max_depth': trial.suggest_int('max_depth', 3, 12),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),
        'gamma': trial.suggest_float('gamma', 1e-8, 20.0, log=True),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),
        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.3, 1.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 100.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 100.0, log=True),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.5, 5.0),
        'max_delta_step': trial.suggest_int('max_delta_step', 0, 10),
        'random_state': 42
    }
    
    model = xgb.XGBClassifier(**params, n_estimators=700)
    cv_scores = cross_val_predict(model, X_train, y_train, cv=5, method='predict', n_jobs=4)
    return custom_objective_score(y_train, cv_scores)

study_xgb = optuna.create_study(direction='maximize')
study_xgb.optimize(xgb_objective, n_trials=100, show_progress_bar=True, n_jobs=1)

# CatBoost with advanced regularization
print("\n2. CatBoost with Advanced Regularization...")
def catboost_objective(trial):
    params = {
        'iterations': 700,
        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),
        'depth': trial.suggest_int('depth', 3, 12),
        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 100.0, log=True),
        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 2.0),
        'random_strength': trial.suggest_float('random_strength', 0.0, 20.0),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.5, 5.0),
        'verbose': False,
        'random_seed': 42
    }
    
    model = cb.CatBoostClassifier(**params)
    cv_scores = cross_val_predict(model, X_train, y_train, cv=5, method='predict', n_jobs=4)
    return custom_objective_score(y_train, cv_scores)

study_cat = optuna.create_study(direction='maximize')
study_cat.optimize(catboost_objective, n_trials=100, show_progress_bar=True, n_jobs=1)

# LightGBM with DART boosting
print("\n3. LightGBM...")
def lightgbm_objective(trial):
    
    params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': trial.suggest_int('num_leaves', 10, 500),
        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.3, 1.0),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.3, 1.0),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 200),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 100.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 100.0, log=True),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.5, 5.0),
        'verbose': -1,
        'random_state': 42
    }
    
    model = lgb.LGBMClassifier(**params, n_estimators=700)
    cv_scores = cross_val_predict(model, X_train, y_train, cv=5, method='predict', n_jobs=-1)
    return custom_objective_score(y_train, cv_scores)

study_lgb = optuna.create_study(direction='maximize')
study_lgb.optimize(lightgbm_objective, n_trials=100, show_progress_bar=True, n_jobs=1)

# Neural Network (MLP)
print("\n4. Neural Network with Advanced Architecture...")
scaler_nn = StandardScaler()
X_train_scaled = scaler_nn.fit_transform(X_train)
X_test_scaled = scaler_nn.transform(X_test)

def mlp_objective(trial):
    params = {
        'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', 
            [(100,), (200,), (100, 50), (200, 100), (300, 150), (200, 100, 50)]),
        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic']),
        'solver': trial.suggest_categorical('solver', ['adam', 'lbfgs']),
        'alpha': trial.suggest_float('alpha', 1e-6, 1e-1, log=True),
        'learning_rate': trial.suggest_categorical('learning_rate', ['constant', 'invscaling', 'adaptive']),
        'max_iter': 1000,
        'random_state': 42,
        'early_stopping': True,
        'validation_fraction': 0.2
    }
    
    if params['solver'] == 'adam':
        params['learning_rate_init'] = trial.suggest_float('learning_rate_init', 1e-5, 1e-1, log=True)
        params['beta_1'] = trial.suggest_float('beta_1', 0.8, 0.99)
        params['beta_2'] = trial.suggest_float('beta_2', 0.9, 0.999)
    
    model = MLPClassifier(**params)
    cv_scores = cross_val_predict(model, X_train_scaled, y_train, cv=5, method='predict', n_jobs=-1)
    return custom_objective_score(y_train, cv_scores)

study_mlp = optuna.create_study(direction='maximize')
study_mlp.optimize(mlp_objective, n_trials=50, show_progress_bar=True, n_jobs=1)

# Advanced SVM with probability calibration
print("\n5. Advanced SVM with Probability Calibration...")
def svm_objective(trial):
    params = {
        'C': trial.suggest_float('C', 1e-4, 1e4, log=True),
        'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']) if trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid']) != 'linear' else 'scale',
        'kernel': trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid', 'linear']),
        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),
        'probability': True,
        'random_state': 42
    }
    
    if params['kernel'] == 'poly':
        params['degree'] = trial.suggest_int('degree', 2, 5)
        params['coef0'] = trial.suggest_float('coef0', 0.0, 10.0)
    elif params['kernel'] == 'sigmoid':
        params['coef0'] = trial.suggest_float('coef0', 0.0, 10.0)
    
    model = SVC(**params)
    cv_scores = cross_val_predict(model, X_train_scaled, y_train, cv=5, method='predict', n_jobs=-1)
    return custom_objective_score(y_train, cv_scores)

study_svm = optuna.create_study(direction='maximize')
study_svm.optimize(svm_objective, n_trials=50, show_progress_bar=True, n_jobs=1)

print(f"\n‚úÖ Base Model Optimization Complete!")
print(f"XGBoost best score: {study_xgb.best_value:.4f}")
print(f"CatBoost best score: {study_cat.best_value:.4f}")
print(f"LightGBM best score: {study_lgb.best_value:.4f}")
print(f"MLP best score: {study_mlp.best_value:.4f}")
print(f"SVM best score: {study_svm.best_value:.4f}")

# Save Optuna studies
print(f"\nüíæ Saving Optuna studies...")
joblib.dump(study_xgb, os.path.join(models_dir, 'study_xgb.pkl'))
joblib.dump(study_cat, os.path.join(models_dir, 'study_cat.pkl'))
joblib.dump(study_lgb, os.path.join(models_dir, 'study_lgb.pkl'))
joblib.dump(study_mlp, os.path.join(models_dir, 'study_mlp.pkl'))
joblib.dump(study_svm, os.path.join(models_dir, 'study_svm.pkl'))

# Save scalers
joblib.dump(scaler_nn, os.path.join(models_dir, 'scaler_nn.pkl'))

print(f"‚úÖ Saved Optuna studies and scalers")

# ============================================================================
# LEVEL 2: STACKING WITH MULTIPLE META-LEARNERS
# ============================================================================
print("\nüèóÔ∏è  LEVEL 2: Stacking with Multiple Meta-Learners...")

# Create optimized base models
base_models = [
    ('xgb', xgb.XGBClassifier(**study_xgb.best_params, n_estimators=700, random_state=42)),
    ('cat', cb.CatBoostClassifier(**study_cat.best_params, verbose=False, random_seed=42)),
    ('lgb', lgb.LGBMClassifier(**study_lgb.best_params, n_estimators=700, verbose=-1, random_state=42)),
    ('mlp', MLPClassifier(**study_mlp.best_params, random_state=42)),
    ('svm', SVC(**study_svm.best_params, probability=True, random_state=42))
]

# Test different meta-learners
meta_learners = {
    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),
    'XGBoost_Meta': xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),
    'LightGBM_Meta': lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, verbose=-1, random_state=42),
    'MLP_Meta': MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42)
}

stacking_results = {}

for meta_name, meta_learner in meta_learners.items():
    print(f"\nTesting {meta_name} as meta-learner...")
    
    # Create preprocessing pipelines for models that need scaling
    from sklearn.pipeline import Pipeline
    
    # Create properly scaled base models for stacking
    scaled_base_models = [
        ('xgb', xgb.XGBClassifier(**study_xgb.best_params, n_estimators=700, random_state=42)),
        ('cat', cb.CatBoostClassifier(**study_cat.best_params, verbose=False, random_seed=42)),
        ('lgb', lgb.LGBMClassifier(**study_lgb.best_params, n_estimators=700, verbose=-1, random_state=42)),
        ('mlp', Pipeline([('scaler', StandardScaler()), ('classifier', MLPClassifier(**study_mlp.best_params, random_state=42))])),
        ('svm', Pipeline([('scaler', StandardScaler()), ('classifier', SVC(**study_svm.best_params, probability=True, random_state=42))]))
    ]
    
    # Create stacking classifier
    stacking_clf = StackingClassifier(
        estimators=scaled_base_models,
        final_estimator=meta_learner,
        cv=5,
        stack_method='predict_proba',
        n_jobs=-1,
        passthrough=False
    )
    
    # Fit stacking classifier
    stacking_clf.fit(X_train, y_train)
    
    # Predictions
    y_pred_stack = stacking_clf.predict(X_test)
    y_proba_stack = stacking_clf.predict_proba(X_test)[:, 1]
    
    # Evaluate
    accuracy = accuracy_score(y_test, y_pred_stack)
    balanced_acc = balanced_accuracy_score(y_test, y_pred_stack)
    f1 = f1_score(y_test, y_pred_stack)
    recall_1 = recall_score(y_test, y_pred_stack, pos_label=1)
    precision_1 = precision_score(y_test, y_pred_stack, pos_label=1)
    
    stacking_results[meta_name] = {
        'accuracy': accuracy,
        'balanced_accuracy': balanced_acc,
        'f1': f1,
        'recall_1': recall_1,
        'precision_1': precision_1,
        'model': stacking_clf,
        'predictions': y_pred_stack,
        'probabilities': y_proba_stack
    }
    
    print(f"  Accuracy: {accuracy:.4f}")
    print(f"  Balanced Accuracy: {balanced_acc:.4f}")
    print(f"  F1 Score: {f1:.4f}")

# Find best meta-learner
best_meta = max(stacking_results.keys(), key=lambda x: stacking_results[x]['accuracy'])
best_stacking_model = stacking_results[best_meta]['model']
best_accuracy = stacking_results[best_meta]['accuracy']

print(f"\nüèÜ Best Meta-Learner: {best_meta} with {best_accuracy:.4f} accuracy")

# Save all stacking models and results
print(f"\nüíæ Saving stacking models...")
for meta_name, results in stacking_results.items():
    model_path = os.path.join(models_dir, f'stacking_model_{meta_name.lower()}.pkl')
    joblib.dump(results['model'], model_path)
    print(f"‚úÖ Saved: stacking_model_{meta_name.lower()}.pkl")

# Save stacking results
results_path = os.path.join(models_dir, 'stacking_results.pkl')
with open(results_path, 'wb') as f:
    pickle.dump(stacking_results, f)
print(f"‚úÖ Saved: stacking_results.pkl")

# ============================================================================
# LEVEL 3: CALIBRATED PREDICTIONS WITH THRESHOLD OPTIMIZATION
# ============================================================================
print("\nüéØ LEVEL 3: Calibrated Predictions with Threshold Optimization...")

# Calibrate the best stacking model
calibrated_clf = CalibratedClassifierCV(
    base_estimator=best_stacking_model,
    method='isotonic',
    cv=5
)

# Fit calibrated model
calibrated_clf.fit(X_train, y_train)

# Save calibrated model
print(f"\nüíæ Saving calibrated model...")
calibrated_model_path = os.path.join(models_dir, 'calibrated_stacking_model.pkl')
joblib.dump(calibrated_clf, calibrated_model_path)
print(f"‚úÖ Saved: calibrated_stacking_model.pkl")

# Get calibrated probabilities
y_proba_calibrated = calibrated_clf.predict_proba(X_test)[:, 1]

# Threshold optimization
thresholds = np.arange(0.1, 0.9, 0.01)
threshold_results = []

for threshold in thresholds:
    y_pred_thresh = (y_proba_calibrated >= threshold).astype(int)
    
    if len(np.unique(y_pred_thresh)) > 1:  # Avoid division by zero
        accuracy = accuracy_score(y_test, y_pred_thresh)
        balanced_acc = balanced_accuracy_score(y_test, y_pred_thresh)
        f1 = f1_score(y_test, y_pred_thresh)
        recall_1 = recall_score(y_test, y_pred_thresh, pos_label=1)
        precision_1 = precision_score(y_test, y_pred_thresh, pos_label=1, zero_division=0)
        
        threshold_results.append({
            'threshold': threshold,
            'accuracy': accuracy,
            'balanced_accuracy': balanced_acc,
            'f1': f1,
            'recall_1': recall_1,
            'precision_1': precision_1
        })

threshold_df = pd.DataFrame(threshold_results)
best_threshold_idx = threshold_df['accuracy'].idxmax()
optimal_threshold = threshold_df.loc[best_threshold_idx, 'threshold']

print(f"Optimal threshold: {optimal_threshold:.3f}")

# Final predictions with optimal threshold
y_pred_final = (y_proba_calibrated >= optimal_threshold).astype(int)

# ============================================================================
# FINAL RESULTS
# ============================================================================
print("\n" + "=" * 80)
print("üèÜ FINAL STACKING ENSEMBLE RESULTS")
print("=" * 80)

final_accuracy = accuracy_score(y_test, y_pred_final)
final_balanced_acc = balanced_accuracy_score(y_test, y_pred_final)
final_f1 = f1_score(y_test, y_pred_final)
final_recall_1 = recall_score(y_test, y_pred_final, pos_label=1)
final_precision_1 = precision_score(y_test, y_pred_final, pos_label=1)

print(f"üìà CALIBRATED STACKING MODEL:")
print(f"Best Meta-Learner: {best_meta}")
print(f"Optimal Threshold: {optimal_threshold:.3f}")
print(f"Accuracy: {final_accuracy:.4f}")
print(f"Balanced Accuracy: {final_balanced_acc:.4f}")
print(f"F1 Score: {final_f1:.4f}")
print(f"D1 Recall: {final_recall_1:.4f}")
print(f"D1 Precision: {final_precision_1:.4f}")

print(f"\nüìä Classification Report:")
print(classification_report(y_test, y_pred_final))

print(f"Confusion Matrix:")
cm_final = confusion_matrix(y_test, y_pred_final)
print(cm_final)

tn, fp, fn, tp = cm_final.ravel()
print(f"\nüéØ Analysis:")
print(f"True Positives (Correctly identified D1): {tp}")
print(f"False Positives (Over-recruit): {fp}")
print(f"False Negatives (Miss talent): {fn}")
print(f"FP:FN Ratio: {fp/(fn+0.001):.2f}")

# Compare with baselines
most_freq_class = y_test.value_counts(normalize=True).max()
print(f"\nNo Information Rate: {most_freq_class:.4f}")
print(f"Improvement over no-info: {final_accuracy - most_freq_class:+.4f}")

if final_accuracy >= 0.80:
    print("üéâ SUCCESS: Achieved 80%+ accuracy target!")
elif final_accuracy >= 0.78:
    print("üéØ CLOSE: Nearly achieved 80% target!")
else:
    print(f"‚ö†Ô∏è Need improvement: {0.80 - final_accuracy:.4f} below 80% target")

print("\n" + "=" * 80)
print("üéâ ADVANCED STACKING ENSEMBLE COMPLETE!")
print("Multi-Level: Base Models ‚Üí Meta-Learner ‚Üí Calibration ‚Üí Threshold Optimization")
print("=" * 80)

print(f"\nüìà Performance Summary:")
print(f"Hierarchical model: 0.7666 accuracy")
print(f"Stacking model: {final_accuracy:.4f} accuracy")
print(f"Improvement: {final_accuracy - 0.7666:+.4f}")
print(f"Target: 0.8000 accuracy")
print(f"Gap to target: {0.8000 - final_accuracy:+.4f}")

# Feature importance from best base model
if hasattr(best_stacking_model.named_estimators_['xgb'], 'feature_importances_'):
    importance_df = pd.DataFrame({
        'feature': X.columns,
        'importance': best_stacking_model.named_estimators_['xgb'].feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nTop 15 Most Important Features:")
    print(importance_df.head(15))
    
    # Save feature importance
    importance_path = os.path.join(models_dir, 'feature_importance.csv')
    importance_df.to_csv(importance_path, index=False)
    print(f"‚úÖ Saved: feature_importance.csv")

# ============================================================================
# COMPREHENSIVE MODEL SAVING AND METADATA
# ============================================================================
print(f"\nüíæ Saving final model configuration and metadata...")

# Save final model configuration
final_config = {
    'best_meta_learner': best_meta,
    'optimal_threshold': optimal_threshold,
    'final_accuracy': final_accuracy,
    'final_balanced_accuracy': final_balanced_acc,
    'final_f1': final_f1,
    'final_recall_1': final_recall_1,
    'final_precision_1': final_precision_1,
    'confusion_matrix': cm_final.tolist(),
    'feature_names': X.columns.tolist(),
    'best_params': {
        'xgb': study_xgb.best_params,
        'cat': study_cat.best_params,
        'lgb': study_lgb.best_params,
        'mlp': study_mlp.best_params,
        'svm': study_svm.best_params
    },
    'training_details': {
        'train_size': len(X_train),
        'test_size': len(X_test),
        'train_d1_rate': y_train.mean(),
        'test_d1_rate': y_test.mean(),
        'n_features': X.shape[1]
    }
}

config_path = os.path.join(models_dir, 'final_model_config.pkl')
with open(config_path, 'wb') as f:
    pickle.dump(final_config, f)
print(f"‚úÖ Saved: final_model_config.pkl")

# Save individual base models (properly scaled) for direct access
print(f"\nüíæ Saving individual base models...")
individual_models = {
    'xgb_model': xgb.XGBClassifier(**study_xgb.best_params, n_estimators=700, random_state=42),
    'cat_model': cb.CatBoostClassifier(**study_cat.best_params, verbose=False, random_seed=42),
    'lgb_model': lgb.LGBMClassifier(**study_lgb.best_params, n_estimators=700, verbose=-1, random_state=42),
    'mlp_model': MLPClassifier(**study_mlp.best_params, random_state=42),
    'svm_model': SVC(**study_svm.best_params, probability=True, random_state=42)
}

# Train and save individual models
individual_models['xgb_model'].fit(X_train, y_train)
individual_models['cat_model'].fit(X_train, y_train)
individual_models['lgb_model'].fit(X_train, y_train)
individual_models['mlp_model'].fit(X_train_scaled, y_train)  # Use scaled data
individual_models['svm_model'].fit(X_train_scaled, y_train)  # Use scaled data

for model_name, model in individual_models.items():
    model_path = os.path.join(models_dir, f'individual_{model_name}.pkl')
    joblib.dump(model, model_path)
    print(f"‚úÖ Saved: individual_{model_name}.pkl")

# Save the scaler used for MLP and SVM
scaler_main_path = os.path.join(models_dir, 'scaler_for_mlp_svm.pkl')
joblib.dump(scaler_nn, scaler_main_path)
print(f"‚úÖ Saved: scaler_for_mlp_svm.pkl")

# Save feature engineering pipeline info
feature_engineering_info = {
    'scaler_cluster': scaler_cluster,
    'kmeans_model': kmeans,
    'regional_weights': region_weights if 'region_weights' in locals() else None,
    'percentile_features': percentile_features,
    'scaler_for_mlp_svm': scaler_nn,  # Add the main scaler here too
    'feature_engineering_steps': [
        'power_speed', 'of_velo_sixty_ratio', 'height_weight',
        'percentile_features', 'power_per_pound', 'exit_to_sixty_ratio', 
        'speed_size_efficiency', 'athletic_index', 'elite_thresholds',
        'multi_tool_features', 'd1_thresholds', 'polynomial_features',
        'regional_advantages', 'feature_clustering'
    ]
}

feature_eng_path = os.path.join(models_dir, 'feature_engineering_pipeline.pkl')
with open(feature_eng_path, 'wb') as f:
    pickle.dump(feature_engineering_info, f)
print(f"‚úÖ Saved: feature_engineering_pipeline.pkl")

# Create comprehensive README
readme_content = f'''# Advanced Stacking Ensemble Outfielder D1 Model

## Model Performance
- **Final Accuracy**: {final_accuracy:.4f}
- **Balanced Accuracy**: {final_balanced_acc:.4f}
- **F1 Score**: {final_f1:.4f}
- **D1 Recall**: {final_recall_1:.4f}
- **D1 Precision**: {final_precision_1:.4f}
- **Best Meta-Learner**: {best_meta}
- **Optimal Threshold**: {optimal_threshold:.3f}

## Model Architecture
1. **Level 1**: 5 Diverse Base Models (XGBoost, CatBoost, LightGBM, MLP, SVM)
2. **Level 2**: Meta-Learning with {best_meta}
3. **Level 3**: Isotonic Calibration + Threshold Optimization

## Files Included
- `calibrated_stacking_model.pkl` - Final calibrated ensemble model (MAIN MODEL)
- `stacking_model_*.pkl` - Individual stacking models for each meta-learner (4 files)
- `individual_*_model.pkl` - Individual base models (5 files)
- `study_*.pkl` - Optuna optimization studies for each base model (5 files)  
- `scaler_nn.pkl` - StandardScaler for neural network (optimization phase)
- `scaler_for_mlp_svm.pkl` - StandardScaler for MLP and SVM models
- `final_model_config.pkl` - Complete model configuration and performance metrics
- `feature_engineering_pipeline.pkl` - Feature engineering components (includes all scalers)
- `feature_importance.csv` - Feature importance rankings
- `stacking_results.pkl` - Results from all meta-learners tested

## Usage
1. Load the calibrated model: `joblib.load('calibrated_stacking_model.pkl')`
2. Apply the same feature engineering pipeline
3. Use optimal threshold {optimal_threshold:.3f} for final predictions
4. Ensure input features match the {X.shape[1]} expected features

## Training Details
- Training samples: {len(X_train)}
- Test samples: {len(X_test)}
- Features: {X.shape[1]}
- Optuna trials: XGB(150), CAT(150), LGB(150), MLP(100), SVM(100)
'''

readme_path = os.path.join(models_dir, 'README.md')
with open(readme_path, 'w') as f:
    f.write(readme_content)
print(f"‚úÖ Saved: README.md")

print(f"\nüéØ ALL MODELS AND METADATA SAVED TO: {models_dir}")
print(f"\nüì¶ Saved Files Summary:")
print("‚îú‚îÄ‚îÄ calibrated_stacking_model.pkl (MAIN MODEL)")
print("‚îú‚îÄ‚îÄ stacking_model_*.pkl (4 files)")
print("‚îú‚îÄ‚îÄ individual_*_model.pkl (5 files)")  
print("‚îú‚îÄ‚îÄ study_*.pkl (5 files)")
print("‚îú‚îÄ‚îÄ scaler_nn.pkl (optimization phase)")
print("‚îú‚îÄ‚îÄ scaler_for_mlp_svm.pkl (production use)")
print("‚îú‚îÄ‚îÄ final_model_config.pkl")
print("‚îú‚îÄ‚îÄ feature_engineering_pipeline.pkl (includes all scalers)")
print("‚îú‚îÄ‚îÄ feature_importance.csv")
print("‚îú‚îÄ‚îÄ stacking_results.pkl")
print("‚îî‚îÄ‚îÄ README.md")
print(f"\n‚úÖ READY FOR PRODUCTION OR FURTHER ANALYSIS!")